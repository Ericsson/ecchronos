#
# Copyright 2024 Telefonaktiebolaget LM Ericsson
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

### ecChronos agent configuration

## Connection
## Properties for connection to Cassandra nodes
##
connection:
  # Configuration for the ThreadPoolTaskExecutor used by ecChronos.
  # This thread pool controls how many concurrent threads the NodeManager can use.
  # The number of threads should be proportional to the number of nodes managed by this instance.
  threadPool:
    ## Minimum number of threads in the pool
    corePoolSize: 4
    ## Maximum number of threads in the pool
    maxPoolSize: 10
    ## Queue capacity for pending tasks
    queueCapacity: 20
    ## The time to keep idle threads alive, in seconds
    keepAliveSeconds: 60
  cql:
    ## Configuration to define Agent Strategy and hosts for ecChronos
    ## to connect to. The application will use the configurations
    ## specified below, connecting to the listed hosts;
    agent:
      ## Each ecChronos instance must have unique name.
      ## (instanceName: unique identifier), that will be used
      ## as ecchronos_id (partition key in nodes_sync table).
      instanceName: unique_identifier
      ## Define the Agent strategy, it can be
      ## - datacenterAware;
      ## - rackAware; and
      ## - hostAware.
      type: datacenterAware
      ## Specifies the datacenter that is considered "local" by the load balancing policy,
      ## The specified datacenter should match with the contact point datacenter
      localDatacenter: datacenter1
      ## Initial contact points list for ecChronos
      ## to establish first connection with Cassandra.
      contactPoints:
        - host: 127.0.0.1
          port: 9042
        - host: 127.0.0.2
          port: 9042

      ## Configuration to define datacenters for ecChronos
      ## to connect to, datacenterAware enable means that
      ## ecChronos will be responsible for all nodes in the
      ## datacenter list.
      datacenterAware:
        datacenters:
          - name: datacenter1
          - name: datacenter2
      ## Configuration to define racks for ecChronos
      ## to connect to, rackAware enable means that
      ## ecChronos will be responsible for all nodes in the
      ## rack list, this configuration is designed to manage
      ## racks on the same datacenter.
      rackAware:
        racks:
          - datacenterName: datacenter1
            rackName: rack1
          - datacenterName: datacenter1
            rackName: rack2
        ## Configuration to define hosts for ecChronos
      ## to connect to, hostAware enable means that
      ## ecChronos will be responsible just for the
      ## specified hosts list.
      hostAware:
        hosts:
          - host: 127.0.0.1
            port: 9042
          - host: 127.0.0.2
            port: 9042
          - host: 127.0.0.3
            port: 9042
          - host: 127.0.0.4
            port: 9042
      # Retry policy used during the creation of a CqlSession.
      # This policy defines how connection attempts should be retried in case
      # of temporary failures when establishing a session with Cassandra.
      retryPolicy:
        ## Max number of attempts ecChronos will try to connect with Cassandra.
        maxAttempts: 5
        ## Delay use to wait between an attempt and another, this value will be multiplied by the current attempt count powered by two.
        ## If the current attempt is 4 and the default delay is 5 seconds, so ((4(attempt) x 2) x 5(default delay)) = 40 seconds.
        ## If the calculated delay is greater than maxDelay, maxDelay will be used instead of the calculated delay.
        delay: 5
        ## Maximum delay before the next connection attempt is made.
        ## Setting it as 0 will disable maxDelay and the delay interval will
        ## be calculated based on the attempt count and the default delay.
        maxDelay: 30
        unit: seconds
      # Schedule configuration for the ReloadSchedulerService, responsible for monitoring
      # Cassandra topology changes during execution. If a topology change is detected,
      # the internal topology state is automatically refreshed.
      reloadSchedule:
        ## Initial delay before the RetrySchedulerService starts after the application launches.
        ## By default, this service would trigger after 1 day and represents the wait time before the service first runs
        initialDelay: 1
        ## Fixed delay between subsequent executions of the RetrySchedulerService.
        ## This value represents the delay time (by default 1 day) between when the service completes one execution
        ## and the time it will be triggered again for another execution.
        ## During each execution, the service will check for unavailable nodes and attempt reconnections as per the retry logic.
        fixedDelay: 1
        ## unit can be milliseconds, seconds, minutes, hours, days.
        unit: days
    ##
    ## The class used to provide CQL connections to Apache Cassandra.
    ## The default provider will be used unless another is specified.
    ##
    provider: com.ericsson.bss.cassandra.ecchronos.application.providers.AgentNativeConnectionProvider
    ##
    ## The class used to provide an SSL context to the NativeConnectionProvider.
    ## Extending this allows to manipulate the SSLEngine and SSLParameters.
    ##
    certificateHandler: com.ericsson.bss.cassandra.ecchronos.application.config.security.ReloadingCertificateHandler
    ##
    ## Specify the interval until the next connection to a node
    ## Unit can be SECONDS, MINUTES, HOURS, DAYS
    ##
    connectionDelay:
      time: 45
      unit: MINUTES
  jmx:
    jolokia:
      #
      # Specifies whether the Jolokia adapter for connecting to JMX objects is enabled or not.
      # Default: false (adapter is disabled if not explicitly configured).
      #
      enabled: false
      #
      # Defines the port used by Jolokia for accessing JMX objects.
      # Default: 8778 (this port will be used if no other port is configured).
      #
      port: 8778
    ##
    ## The class used to provide JMX connections to Apache Cassandra.
    ## The default provider will be used unless another is specified.
    ##
    provider: com.ericsson.bss.cassandra.ecchronos.application.providers.AgentJmxConnectionProvider
    retryPolicy:
      ## Max number of attempts ecChronos will try to connect with Cassandra.
      maxAttempts: 5
      ## Delay use to wait between an attempt and another, this value will be multiplied by the current attempt count powered by two.
      ## If the current attempt is 4 and the default delay is 5 seconds, so ((4(attempt) x 2) x 5(default delay)) = 40 seconds.
      ## If the calculated delay is greater than maxDelay, maxDelay will be used instead of the calculated delay.
      delay:
        start: 5
        ## Maximum delay before the next connection attempt is made.
        ## Setting it as 0 will disable maxDelay and the delay interval will
        ## be calculated based on the attempt count and the default delay.
        max: 30
        ## unit can be milliseconds, seconds, minutes, hours, days.
        unit: seconds
      # RetrySchedulerService schedule starts after the application launches.
      retrySchedule:
        ## Initial delay before the RetrySchedulerService starts after the application launches.
        ## By default, this service would trigger after 1 day and represents the wait time before the service first runs
        initialDelay: 1
        ## Fixed delay between subsequent executions of the RetrySchedulerService.
        ## This value represents the delay time (by default 1 day) between when the service completes one execution
        ## and the time it will be triggered again for another execution.
        ## During each execution, the service will check for unavailable nodes and attempt reconnections as per the retry logic.
        fixedDelay: 1
        ## unit can be milliseconds, seconds, minutes, hours, days.
        unit: days

## Repair configuration
## This section defines default repair behavior for all tables.
##
repair:
  ##
  ## A class for providing repair configuration for tables.
  ## The default FileBasedRepairConfiguration uses a schedule.yml file to define per-table configurations.
  ##
  provider: com.ericsson.bss.cassandra.ecchronos.application.config.repair.FileBasedRepairConfiguration
  ##
  ## How often repairs should be triggered for tables.
  ##
  interval:
    time: 7
    unit: days
  ##
  ## Initial delay for new tables. New tables are always assumed to have been repaired in the past by the interval.
  ## However, a delay can be set for the first repair. This will not affect subsequent repairs and defaults to one day.
  ##
  initial_delay:
    time: 1
    unit: days
  ##
  ## The unit of time granularity for priority calculation, can be HOURS, MINUTES, or SECONDS.
  ## This unit is used in the calculation of priority.
  ## Default is HOURS for backward compatibility.
  ## Ensure to pause repair operations prior to changing the granularity.
  ## Not doing so may lead to inconsistencies as some ecChronos instances
  ## could have different priorities compared to others for the same repair.
  ## Possible values are HOURS, MINUTES, or SECONDS.
  ##
  priority:
    granularity_unit: HOURS
  ##
  ## Specifies the type of lock to use for repairs.
  ## "vnode" will lock each node involved in a repair individually and increase the number of
  ## parallel repairs that can run in a single data center.
  ## "datacenter" will lock each data center involved in a repair and only allow a single repair per data center.
  ## "datacenter_and_vnode" will combine both options and allow a smooth transition between them without allowing
  ## multiple repairs to run concurrently on a single node.
  ##
  lock_type: vnode
  ##
  ## Specifies the unwind ratio to smooth out the load that repairs generate.
  ## This value is a ratio between 0 -> 100% of the execution time of a repair session.
  ##
  ## 100% means that the executor will wait to run the next session for as long time as the previous session took.
  ## The 'unwind_ratio' setting configures the wait time between repair tasks as a proportion of the previous task's execution time.
  ##
  ## Examples:
  ## - unwind_ratio: 0
  ##   Explanation: No wait time between tasks. The next task starts immediately after the previous one finishes.
  ##   Total Repair Time: T1 (10s) + T2 (20s) = 30 seconds.
  ##
  ## - unwind_ratio: 1.0 (100%)
  ##   Explanation: The wait time after each task equals its duration.
  ##   Total Repair Time: T1 (10s + 10s wait) + T2 (20s + 20s wait) = 60 seconds.
  ##
  ## - unwind_ratio: 0.5 (50%)
  ##   Explanation: The wait time is half of the task's duration.
  ##   Total Repair Time: T1 (10s + 5s wait) + T2 (20s + 10s wait) = 45 seconds.
  ##
  ##  A higher 'unwind_ratio' reduces system load by adding longer waits, but increases total repair time.
  ##  A lower 'unwind_ratio' speeds up repairs but may increase system load.
  ##
  unwind_ratio: 0.0
  ##
  ## Specifies the lookback time for when the repair_history table is queried to get initial repair state at startup.
  ## The time should match the "expected TTL" of the system_distributed.repair_history table.
  ##
  history_lookback:
    time: 30
    unit: days
  ##
  ## Specifies a target for how much data each repair session should process.
  ## This is only supported if using 'vnode' as repair_type.
  ## This is an estimation assuming uniform data distribution among partition keys.
  ## The value should be either a number or a number with a unit of measurement:
  ## 12  (12 B)
  ## 12k (12 KiB)
  ## 12m (12 MiB)
  ## 12g (12 GiB)
  ##
  size_target:
  ##
  ## Specifies the repair history provider used to determine repair state.
  ## The "cassandra" provider uses the repair history generated by the database.
  ## The "upgrade" provider is an intermediate state reading history from "cassandra" and producing history for "ecc"
  ## The "ecc" provider maintains and uses an internal repair history in a dedicated table.
  ## The main context for the "ecc" provider is an environment where the ip address of nodes might change.
  ## Possible values are "ecc", "upgrade" and "cassandra".
  ##
  ## The keyspace parameter is only used by "ecc" and "upgrade" and points to the keyspace where the custom
  ## 'repair_history' table is located.
  ##
  history:
    provider: ecc
    keyspace: ecchronos
  ##
  ## Specifies if tables with TWCS (TimeWindowCompactionStrategy) should be ignored for repair
  ##
  ignore_twcs_tables: false
  ##
  ## Specifies the backoff time for a job.
  ## This is the time that the job will wait before trying to run again after failing.
  ##
  backoff:
    time: 30
    unit: MINUTES
  ##
  ## Specifies the default repair_type.
  ## Possible values are: vnode, parallel_vnode, incremental
  ## vnode = repair 1 vnode at a time (supports size_target to split the vnode further, in this case there will be 1 repair session per subrange)
  ## parallel_vnode = repair vnodes in parallel, this will combine vnodes into a single repair session per repair group
  ## incremental = repair vnodes incrementally (incremental repair)
  ##
  repair_type: vnode

run_policy:
  time_based:
    ##
    ## The keyspace used for the time based run policy tables.
    ##
    keyspace: ecchronos

scheduler:
  ##
  ## Specifies the frequency the scheduler checks for work to be done
  ##
  frequency:
    time: 30
    unit: SECONDS

rest_server:
  ##
  ## The host and port used for the HTTP server
  ##
  host: localhost
  port: 8080

lock_factory:
  cas:
    ##
    ## The keyspace used for the CAS lock factory tables.
    ##
    keyspace: ecchronos
    ##
    ## The number of seconds until the lock failure cache expires.
    ## If an attempt to secure a lock is unsuccessful,
    ## all subsequent attempts will be failed until
    ## the cache expiration time is reached.
    ##
    cache_expiry_time_in_seconds: 30
    ##
    ## Allow to override consistency level for LWT (lightweight transactions). Possible values are:
    ## "SERIAL" - Use SERIAL consistency for LWT regardless of agent type.
    ## "LOCAL" - Use LOCAL_SERIAL consistency for LWT regardless agent type.
    ##
    ## If an agent type other than datacenterAware and LOCAL is used, all locks will be managed locally within each datacenter.
    ## I.e There's a risk that multiple nodes in different datacenters will be able to lock the
    ## same nodes causing multiple repairs on the same range/node at the same time.
    ##
    consistencySerial: "SERIAL"
